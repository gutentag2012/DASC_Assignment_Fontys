---
title: "BKA_Kriminalstatistik_2019_data_analysis"
author: "Peter von Bodelschwingh, Joshua Gawenda"
date: "12 12 2020"
output:
  pdf_document: default
  pdf: default
---

```{r setup, include=FALSE}
library(readxl)
library(dplyr)
library(sjmisc)
library(tidyverse)
library(GDINA)
knitr::opts_chunk$set(echo = TRUE)
```



# Introduction
This dataset is taken from the  Bundeskriminalamt - the leading institution of crime detection in germany.
The original dataset can be found here: 
[BKA Dataset](https://www.bka.de/DE/AktuelleInformationen/StatistikenLagebilder/PolizeilicheKriminalstatistik/PKS2019/PKSTabellen/LandFalltabellen/landFalltabellen.html?nn=130872)

It contains data about all crimes recorded in 2019. This analysis divides the statistics into all 16 german provinces. The goal of this analysis is to present the differences between these provinces by categories of crime, population, sucessful and non successfull enlisted crimes. Further documentation is provided in the "Interpretationshilfen" subfolder of this project.  

The original excel file can be found in this repository as well. See "PKS_crime_statistics.xlsx". 


## Import
The first step we did was to divide the Overview Sheet into subsheets that contain all data by the province. In order to make sure the importing into R is done correctly, we removed line one til seven so only the Nr of the column is recognized as header, by limiting the range. 
 
```{r}
library(readxl)
originalSet <- read_excel("DataSets/PKS_crime_statistics.xlsx", sheet = "Data",
range = "A8:U18777") 
sumKeys <- read_excel("DataSets/PKS_crime_statistics.xlsx", sheet = "Sumkeys")

```

## Rename columns
as you can see here the column names are not that descriptive anymore: 
```{r}
names(originalSet)
```
Thats why we are going to rename the columns back to the original name of the dataset now. 
```{r}
originalSet <- originalSet %>% 
                rename(
                  key = '1',
                  crime = '2',
                  province = '3',
                  detected_cases = '4',
                  detected_cases_percent = '5',
                  not_executed_cases = '6',
                  not_executed_cases_percent = '7',
                  distribution_under_20K = '8',
                  distribution_20K_to_100K = '9',
                  distribution_100K_to_500K = '10',
                  distribution_over_500K = '11',
                  distribution_unknown = '12',
                  gun_threatened = '13',
                  gun_shot = '14',
                  solved_cases = '15',
                  solved_cases_percent = '16',
                  suspects = '17',
                  male = '18',
                  female = '19',
                  non_german ='20',
                  non_german_percent = '21'
                  )
```
 

### Decouple

First step: remove "N" values, some keys are safed as "NA", they will also be removed,because we keep "Y" values only.
```{r}
sumKeys <- sumKeys %>% filter(grepl("Y",is_sum_key))
```



Remove keys that determine sum values:
TODO: add more documentation, explain sumkeys, explain retrieval process 

```{r}
filteredKeys <- c()
visited <- c()
for (key1 in sumKeys$key) {
  visited <- append(visited, key1)
  for (key2 in sumKeys$key) {
    if (!key2 %in% visited) {
      if (regexpr(paste("^", str_remove(key2, "0+$"), sep = ""), key1)[1] == 1) {
        filteredKeys <- append(filteredKeys, key2)
      }
    }
  }
}
```


```{r}
totalValues <- merge(originalSet,sumKeys,by = "key")
totalValues <- totalValues %>% filter(grepl("Bundesrepublik Deutschland",province))
sum(totalValues$detected_cases)
```

```{r}

# todo: change to remove 141100,231200,133000
# add doc 
  

  totalValues <- filter(totalValues,!(key %in% c("141100","231200","133000")))

sum(totalValues$detected_cases)
```

 




Outsource values assigned to germany as province into gerSet
```{r}
gerSet <- originalSet %>%  filter(grepl("Bundesrepublik Deutschland",province))
originalSet <- originalSet %>% filter(!grepl("Bundesrepublik Deutschland",province))
originalSet
```


## Tidy
### Check non null
First of all we proof that the original Set does not contain any null values: 
```{r}
nonNullValue <- originalSet %>% filter_at(vars(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21),any_vars(is.na(.)))
nrow(nonNullValue)
```

According to the three interrelated rules this set can be considered as tidy now because:
    Each variable has its own column.
    Each observation has its own row.
    Each value has its own cell.

### Remove calculated columns
Since we want to keep our analysis as performant as possible we also remove all calculated columns:
```{r}
originalSet <- originalSet %>% select('1':'4','15','6','8':'14','17':'20')
```


## Creating subsets of the provinces
After proving the set does not contain null values, we will remove all entrys that show total sums for germany and not for a province. See "




Second: we proof that the sum of all datasets is equal to origin: 


## Transform
## Visualise 
## Model 




